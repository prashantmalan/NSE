{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ4fznyoDitXT224peODo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantmalan/NSE/blob/main/DQ_20241014.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToVl0Tz7Ff-3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def read_data(transaction_url, classification_url):\n",
        "    # Load the datasets\n",
        "    transaction_data = pd.read_csv(transaction_url)\n",
        "    column_classification = pd.read_csv(classification_url)\n",
        "    return transaction_data, column_classification\n",
        "\n",
        "def preprocess_data(transaction_data, column_classification):\n",
        "    # Clean the data\n",
        "    transaction_data = transaction_data[~transaction_data.applymap(lambda x: ';' in str(x)).any(axis=1)]\n",
        "    transaction_data.reset_index(drop=True, inplace=True)\n",
        "    transaction_data = transaction_data.applymap(lambda x: str(x).replace(',', '') if isinstance(x, str) else x)\n",
        "    transaction_data = transaction_data.applymap(lambda x: str(x).replace('+', '') if isinstance(x, str) else x)\n",
        "    transaction_data = transaction_data[~transaction_data.applymap(lambda x: ';' in str(x)).any(axis=1)]\n",
        "\n",
        "    # Feature Engineering\n",
        "    feature_categories = column_classification.set_index('Column')['Type'].to_dict()\n",
        "    numeric_features = [col for col, cat in feature_categories.items() if cat == 'Amt']\n",
        "    numeric_features = [col for col in numeric_features if col in transaction_data.columns]\n",
        "\n",
        "    # Check for columns with all NaN values\n",
        "    all_nan_columns = transaction_data[numeric_features].columns[transaction_data[numeric_features].isna().all()].tolist()\n",
        "    transaction_data[all_nan_columns] = 0\n",
        "\n",
        "    return transaction_data, numeric_features\n",
        "\n",
        "def predict_anomalies(transaction_data, numeric_features):\n",
        "    # Create a pipeline for preprocessing and anomaly detection\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('isolation_forest', IsolationForest(contamination=0.01, random_state=42))\n",
        "    ])\n",
        "\n",
        "    anomaly_scores_df = pd.DataFrame(index=transaction_data.index)\n",
        "    for feature in numeric_features:\n",
        "        feature_data = transaction_data[[feature]].copy()\n",
        "        scores = pipeline.fit_predict(feature_data)\n",
        "        anomaly_scores_df[feature] = scores\n",
        "\n",
        "    anomaly_scores_df['Product name'] = transaction_data['Product name']\n",
        "    anomaly_scores_df['Action type'] = transaction_data['Action type']\n",
        "    return anomaly_scores_df\n",
        "\n",
        "def plot_anomalies(transaction_data, anomaly_scores_df, numeric_features):\n",
        "    n_features = len(numeric_features)\n",
        "    n_cols = 4\n",
        "    n_rows = int(np.ceil(n_features / n_cols))\n",
        "    fig = make_subplots(rows=n_rows, cols=n_cols, subplot_titles=numeric_features, horizontal_spacing=0.05, vertical_spacing=0.05)\n",
        "\n",
        "    for i, feature in enumerate(numeric_features):\n",
        "        row = i // n_cols + 1\n",
        "        col = i % n_cols + 1\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=anomaly_scores_df.index[anomaly_scores_df[feature] == 1],\n",
        "            y=transaction_data[feature][anomaly_scores_df[feature] == 1],\n",
        "            mode='markers',\n",
        "            name='Normal',\n",
        "            customdata=anomaly_scores_df[anomaly_scores_df[feature] == 1][['Product name', 'Action type']],\n",
        "            hovertemplate='Product name: %{customdata[0]}<br>Action type: %{customdata[1]}<br>Value: %{y}<extra></extra>',\n",
        "            marker=dict(size=8, color='green', opacity=0.7)\n",
        "        ), row=row, col=col)\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=anomaly_scores_df.index[anomaly_scores_df[feature] == -1],\n",
        "            y=transaction_data[feature][anomaly_scores_df[feature] == -1],\n",
        "            mode='markers',\n",
        "            name='Anomalous',\n",
        "            customdata=anomaly_scores_df[anomaly_scores_df[feature] == -1][['Product name', 'Action type']],\n",
        "            hovertemplate='Product name: %{customdata[0]}<br>Action type: %{customdata[1]}<br>Value: %{y}<extra></extra>',\n",
        "            marker=dict(size=8, color='red', opacity=0.7)\n",
        "        ), row=row, col=col)\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='Anomaly Scores for Each Feature',\n",
        "        showlegend=False,\n",
        "        hovermode='closest',\n",
        "        font=dict(size=10),\n",
        "        autosize=False,\n",
        "        width=1500,\n",
        "        height=1200\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "# Example usage\n",
        "transaction_data, column_classification = read_data(\n",
        "    'https://raw.githubusercontent.com/prashantmalan/NSE/main/Pm_CFTC_2017649.csv',\n",
        "    'https://raw.githubusercontent.com/prashantmalan/NSE/main/col_cat_5.csv'\n",
        ")\n",
        "transaction_data, numeric_features = preprocess_data(transaction_data, column_classification)\n",
        "anomaly_scores_df = predict_anomalies(transaction_data, numeric_features)\n",
        "plot_anomalies(transaction_data, anomaly_scores_df, numeric_features)"
      ]
    }
  ]
}